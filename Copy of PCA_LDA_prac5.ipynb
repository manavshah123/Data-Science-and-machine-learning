{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of PCA_LDA_prac5.ipynb","provenance":[{"file_id":"1nyuU1rK5CWLGeqJLtjrHvEoQ3mZN-tBq","timestamp":1614424571520}],"collapsed_sections":[],"mount_file_id":"1nyuU1rK5CWLGeqJLtjrHvEoQ3mZN-tBq","authorship_tag":"ABX9TyOOVukRfCNCd+AdWqjY/Iik"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3bqWttPhVzq","executionInfo":{"status":"ok","timestamp":1614417270694,"user_tz":-330,"elapsed":626,"user":{"displayName":"Manav Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjU1Zr3mWeLX1e0ffynrvOVQUSVYw5aXhXlT6vnpBc=s64","userId":"05688128739644841902"}},"outputId":"ece43cef-c5b8-4dbc-d8b8-7991df2be519"},"source":["import pandas as pd\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","\r\n","dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Dataset/Wine.csv')\r\n","dataset.corr()\r\n","\r\n","x = dataset.iloc[:,:-1].values\r\n","y = dataset.iloc[:,-1].values\r\n","\r\n","from sklearn.model_selection import train_test_split\r\n","x_train, x_test, y_train, y_test =train_test_split(x,y,test_size=0.25,random_state=0)\r\n","\r\n","from sklearn.preprocessing import StandardScaler\r\n","sc = StandardScaler()\r\n","x_train = sc.fit_transform(x_train)\r\n","x_test = sc.transform(x_test)\r\n","\r\n","##### feature selection - FFS, BFE, ....\r\n","\r\n","##### feature extrection -PCA -principal component Analysis \r\n","##### LDA - Linear Discremeinet Analysis \r\n","##### k-pca -kernel pca\r\n","\r\n","##### Apply PCA\r\n","\r\n","from sklearn.decomposition import PCA\r\n","pca = PCA(n_components = 2)\r\n","x_train = pca.fit_transform(x_train)\r\n","x_test = pca.transform(x_test)\r\n","\r\n","from sklearn.linear_model import LogisticRegression\r\n","model = LogisticRegression(random_state = 0)\r\n","model.fit(x_train, y_train)\r\n","\r\n","y_pred = model.predict(x_test)\r\n","\r\n","#making the confusion matrix\r\n","from sklearn.metrics import confusion_matrix\r\n","cm = confusion_matrix(y_test, y_pred)\r\n","print((cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1]) * 100)\r\n","\r\n","from sklearn.metrics import classification_report\r\n","print(classification_report(y_test, y_pred))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["97.2972972972973\n","              precision    recall  f1-score   support\n","\n","           1       0.94      1.00      0.97        16\n","           2       1.00      0.95      0.98        21\n","           3       1.00      1.00      1.00         8\n","\n","    accuracy                           0.98        45\n","   macro avg       0.98      0.98      0.98        45\n","weighted avg       0.98      0.98      0.98        45\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vS7Oj7fKxJTw","executionInfo":{"status":"ok","timestamp":1614418114152,"user_tz":-330,"elapsed":1064,"user":{"displayName":"Manav Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjU1Zr3mWeLX1e0ffynrvOVQUSVYw5aXhXlT6vnpBc=s64","userId":"05688128739644841902"}}},"source":["#n_component = 4\r\n","\r\n","#k-nn\r\n","#svm\r\n","#decision tree\r\n","#random forest\r\n","#native Bayes"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qe3M1tbSxn_f","executionInfo":{"status":"ok","timestamp":1614417889549,"user_tz":-330,"elapsed":987,"user":{"displayName":"Manav Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjU1Zr3mWeLX1e0ffynrvOVQUSVYw5aXhXlT6vnpBc=s64","userId":"05688128739644841902"}},"outputId":"c9bf542d-0e5e-4468-a5f9-2d1e0b71615e"},"source":["import pandas as pd\r\n","import numpy as np\r\n","\r\n","dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Dataset/Wine.csv')\r\n","dataset.corr()\r\n","\r\n","x = dataset.iloc[:,:-1].values\r\n","y = dataset.iloc[:,-1].values\r\n","\r\n","from sklearn.model_selection import train_test_split\r\n","x_train, x_test, y_train, y_test =train_test_split(x,y,test_size=0.25,random_state=0)\r\n","\r\n","from sklearn.preprocessing import StandardScaler\r\n","sc = StandardScaler()\r\n","x_train = sc.fit_transform(x_train)\r\n","x_test = sc.transform(x_test)\r\n","\r\n","##### Apply LDA\r\n","\r\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\r\n","\r\n","lda = LinearDiscriminantAnalysis(n_components = 2)\r\n","\r\n","x_train = lda.fit_transform(x_train, y_train)\r\n","x_test = lda.transform(x_test)\r\n","\r\n","from sklearn.linear_model import LogisticRegression\r\n","model = LogisticRegression(random_state = 0)\r\n","model.fit(x_train, y_train)\r\n","\r\n","y_pred = model.predict(x_test)\r\n","\r\n","#making the confusion matrix\r\n","from sklearn.metrics import confusion_matrix\r\n","cm = confusion_matrix(y_test, y_pred)\r\n","\r\n","print((cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1]) * 100)\r\n","\r\n","from sklearn.metrics import classification_report\r\n","print(classification_report(y_test, y_pred))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["100.0\n","              precision    recall  f1-score   support\n","\n","           1       1.00      1.00      1.00        16\n","           2       1.00      1.00      1.00        21\n","           3       1.00      1.00      1.00         8\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n"],"name":"stdout"}]}]}